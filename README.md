# 🪪 SecurityModelCards
“Security Model Cards” for Reporting the Security Posture of Internally Developed Machine Learning Models or Systems

👨🏻‍💻 Author: Ron F. Del Rosario  
📧 E-mail: ronsurf23@gmail.com    
🛜 LinkedIn: www.linkedin.com/in/ronaldfloresdelrosario  

🚀 This concept was initially published as public comment via Request for Information (RFI) Related to NIST’s Assignments Under
Sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence (Sections 4.1, 4.5, and 11):
https://www.regulations.gov/comment/NIST-2023-0009-0105

📖 The Security Model Cards concept is also featured in the recently published book (July 26, 2024) "Adversarial AI Attacks, Mitigations, and Defense Strategies: A Cybersecurity Professional's Guide to AI Attacks, Threat Modeling, and Securing AI with MLSecOps" By John Sotiropoulos.  Book is available for purchase in Amazon: https://a.co/d/2LVNvXC  

> [!NOTE] 
> The proof-of-concept (POC) Python code "SecMoldeCard.py" is very basic but you get the idea.  Feel free to customize.  The goal is to automate the generation of Security Model Cards to benefit developers and security engineers, ideally as part of your development and build processes.

> [!NOTE]
> I am currently using a customized and more advanced version of this Security Model Cards concept at my current work where I serve as the Chief Security Architect, focusing on AI/ML Systems.
> The use of Security Model Cards in large organizations helps promote visibility, transparency, and understanding of ML Models and AI Systems in general within product security organizations.    

> [!TIP]
> Product security teams often struggle when it comes to conducting security reviews and threat modeling of ML Models or AI Systems due to a lack of foundational knowledge about the system that
> they need to review.  This is where Model Cards shine, and can easily be repurposed to include a security considerations section that will benefit both AI/ML developers and security teams.